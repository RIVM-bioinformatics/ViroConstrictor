import logging
import os
import pprint
import sys

import AminoExtract
import numpy as np
import pandas as pd
import yaml
from Bio import SeqIO, SeqRecord
from snakemake.utils import Paramspace, min_version
from snakemake_interface_executor_plugins.settings import DeploymentMethod

import ViroConstrictor
from ViroConstrictor.workflow.helpers.containers import get_hash
from ViroConstrictor.workflow.helpers.directories import *
from ViroConstrictor.workflow.helpers.generic_workflow_methods import (
    read_fasta,
    segmented_ref_groups,
)
from ViroConstrictor.workflow.helpers.presets import get_preset_parameter

min_version("9.5")
# Elevate the log level of all output generated by the snakemake.logging module to CRITICAL in order to suppress it when snakemake is calling itself in a downstream process.
if "--snakefile" in sys.argv:
    logging.getLogger("snakemake.logging").setLevel(logging.CRITICAL)
VC_STAGE = "MATCHREF"

SAMPLES = {}
with open(config["sample_sheet"]) as sample_sheet_file:
    SAMPLES = yaml.safe_load(sample_sheet_file)

container_base_path = workflow.deployment_settings.apptainer_prefix if not None else ""

samples_df = (
    pd.DataFrame(SAMPLES)
    .transpose()
    .reset_index()
    .rename(columns=dict(index="sample", VIRUS="Virus"))
)
samples_df = segmented_ref_groups(samples_df)
samples_df = samples_df.explode("segment")
p_space = Paramspace(
    samples_df[["Virus", "segment", "sample"]], filename_params=["sample"]
)
wc_folder = "/".join(p_space.wildcard_pattern.split("/")[:-1]) + "/"


def low_memory_job(wildcards, threads, attempt):
    if config["computing_execution"] == "local":
        return min(attempt * threads * 1 * 1000, config["max_local_mem"])
    return attempt * threads * 1 * 1000


def medium_memory_job(wildcards, threads, attempt):
    if config["computing_execution"] == "local":
        return min(attempt * threads * 2 * 1000, config["max_local_mem"])
    return attempt * threads * 2 * 1000


def high_memory_job(wildcards, threads, attempt):
    if config["computing_execution"] == "local":
        return min(attempt * threads * 4 * 1000, config["max_local_mem"])
    return attempt * threads * 4 * 1000


def workflow_script_path(relative_path):
    basepath = workflow.basedir
    return os.path.join(basepath, relative_path)


def workflow_environment_path(filename):
    basepath = os.path.dirname(
        workflow.basedir
    )  # moves up one directory from the workflow.basedir
    return os.path.join(basepath, conda_envs, filename)


wildcard_constraints:
    # regular expression to match only alphanumeric characters, underscores, dashes, and dots. exclude '/' and only match the first part of the string.
    segment="[\w\-\.\d]+",
    Virus="[\w\-\.\d]+",
    sample="[\w\-\.\d]+",


localrules:
    all,


rule all:
    input:
        f"{datadir}" "match_ref_results.pkl",
        expand(
            f"{datadir}{matchref}" "{sample}_primers.bed",
            sample=p_space.dataframe["sample"],
        ),
        expand(
            f"{datadir}{matchref}" "{sample}_refs.fasta",
            sample=p_space.dataframe["sample"],
        ),
        expand(
            f"{datadir}{matchref}" "{sample}_feats.gff",
            sample=p_space.dataframe["sample"],
        ),


# preparatory steps
include: workflow.source_path("components/preparation.references.smk")
# selection steps
include: workflow.source_path("components/selection.alignment.smk")
include: workflow.source_path("components/selection.reference.smk")
# filtering steps
include: workflow.source_path("components/filter.features.smk")
include: workflow.source_path("components/filter.primers.smk")


# singular end rule that concatenates all the results into a single file
rule concat_frames:
    input:
        set(
            expand(
                f"{datadir}{matchref}" "{sample}_step2.csv",
                sample=p_space.dataframe["sample"],
            )
        ),
    output:
        f"{datadir}" "match_ref_results.pkl",
    threads: 1
    resources:
        mem_mb=low_memory_job,
        runtime=55,
    shell:
        """
        python -c \"import pandas as pd; import sys; df = pd.concat([pd.read_csv(f, keep_default_na=False) for f in sys.argv[1:-1]]); df.to_pickle(sys.argv[-1])\" {input} {output}
        """


onsuccess:
    logging.info(f"{'='*20} [green] Finished Match-reference process [/green] {'='*20}")
    logging.info(
        "[green]Finalizing the results and continuing with the main analysis workflow[/green]"
    )
    return True


onerror:
    logging.error(
        "[bold red]An error occurred during the ViroConstrictor match-reference process.[/bold red]"
    )
    logging.error(
        "[bold red]Shutting down... Please check all the inputs and logfiles for any abnormalities and try again.[/bold red]"
    )
    return False
