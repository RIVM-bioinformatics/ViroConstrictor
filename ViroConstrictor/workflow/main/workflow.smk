import logging
import os
import pprint
import sys
from pathlib import Path

import AminoExtract
import numpy as np
import pandas as pd
import yaml
from Bio import SeqIO
from snakemake.utils import Paramspace, min_version
from snakemake_interface_executor_plugins.settings import DeploymentMethod

import ViroConstrictor
from ViroConstrictor.workflow.helpers.containers import get_hash
from ViroConstrictor.workflow.helpers.directories import *
from ViroConstrictor.workflow.helpers.generic_workflow_methods import (
    get_aminoacid_features,
    get_reference_header,
    list_aminoacid_result_outputs,
)
from ViroConstrictor.workflow.helpers.presets import get_preset_parameter

min_version("9.5")
# Elevate the log level of all output generated by the snakemake.logging module to CRITICAL in order to suppress it when snakemake is calling itself in a downstream process.
if "--snakefile" in sys.argv:
    logging.getLogger("snakemake.logging").setLevel(logging.CRITICAL)


VC_STAGE = "MAIN"

SAMPLES = {}
with open(config["sample_sheet"]) as sample_sheet_file:
    SAMPLES = yaml.safe_load(sample_sheet_file)

container_base_path = workflow.deployment_settings.apptainer_prefix if not None else ""

samples_df = pd.DataFrame(SAMPLES).transpose().reset_index().rename(columns=dict(index="sample", VIRUS="Virus"))
samples_df["RefID"] = samples_df["REFERENCE"].apply(get_reference_header)
samples_df = get_aminoacid_features(samples_df.explode("RefID"))
# samples_df = get_aminoacid_features(samples_df)
p_space = Paramspace(samples_df[["Virus", "RefID", "sample"]], filename_params=["sample"])
wc_folder = "/".join(p_space.wildcard_pattern.split("/")[:-1]) + "/"

# These memory functions are tested in tests/unit/test_dynamic_memory.py
# However, because this is a snakefile instead of a python file, they cannot be imported
# So when these functions are changed, please make sure to also change them in the tests.
def low_memory_job(wildcards, threads, attempt): 
    if config["computing_execution"] == "local":
        return min(attempt * threads * 1 * 1000, config["max_local_mem"])
    return attempt * threads * 1 * 1000

def medium_memory_job(wildcards, threads, attempt):
    if config["computing_execution"] == "local":
        return min(attempt * threads * 2 * 1000, config["max_local_mem"])
    return attempt * threads * 2 * 1000

def high_memory_job(wildcards, threads, attempt):
    if config["computing_execution"] == "local":
        return min(attempt * threads * 4 * 1000, config["max_local_mem"])
    return attempt * threads * 4 * 1000

# time allocation functions. These are logarithmic to compensate for O(n^2) algorithms in some steps.
# most steps will not need more than a couple of minutes for the average dataset.
# However, to accommodate the occasional very large sample, we scale up the time allocation quickly with each attempt.
def low_runtime_job(wildcards, attempt):
    return attempt * attempt * 2

def medium_runtime_job(wildcards, attempt):
    return attempt * attempt * 15

def high_runtime_job(wildcards, attempt):
    return attempt * attempt * 30


def workflow_script_path(relative_path):
    basepath = workflow.basedir
    return os.path.join(basepath, relative_path)


def workflow_environment_path(filename):
    basepath = os.path.dirname(workflow.basedir)  # moves up one directory from the workflow.basedir
    return os.path.join(basepath, conda_envs, filename)


# construct all rule is exists in this file instead of the generic_workflow_methods helperfile as this function is exclusively used for the `all` rule in the entrypoint workflow.
def construct_all_rule(p_space):
    multiqc = f"{res}multiqc.html"
    folders = expand(
        f"{res}{wc_folder}",
        zip,
        RefID=p_space.RefID,
        Virus=p_space.Virus,
    )
    aa_feat_files = list_aminoacid_result_outputs(samples_df)

    base_results_files = expand(
        "{folder}{file}",
        folder=folders,
        file=[
            "consensus.fasta",
            "mutations.tsv",
            "Width_of_coverage.tsv",
            "Amplicon_coverage.csv",
        ],
    )
    
    # Add combined results by virus as targets (in existing Virus~ directories)
    # Note: combined is a Python variable from directories.py, not a Snakemake wildcard
    combined_by_virus = expand(
        f"{res}Virus~{{Virus}}/{combined}{{file}}",
        Virus=samples_df["Virus"].unique(),
        file=[
            "consensus.fasta",
            "mutations.tsv",
            "Width_of_coverage.tsv",
            "Amplicon_coverage.csv",
        ],
    )
    
    # Add combined results for all samples as targets
    combined_all_samples = [
        f"{res}{combined}{all_samples}all_consensus.fasta",
        f"{res}{combined}{all_samples}all_mutations.tsv",
        f"{res}{combined}{all_samples}all_width_of_coverage.tsv",
        f"{res}{combined}{all_samples}all_amplicon_coverage.csv",
    ]

    return [multiqc] + base_results_files + aa_feat_files + combined_by_virus + combined_all_samples


wildcard_constraints:
    # regular expression to match only alphanumeric characters, underscores, dashes, and dots. exclude '/' and only match the first part of the string.
    RefID=r"[\w\-\.\d]+",
    Virus=r"[\w\-\.\d]+",
    # regular expression to match only alphanumeric characters, underscores, dashes. exclude '/' and only match the first part of the string.
    sample=r"[\w\-\.\d]+",


localrules:
    all,


rule all:
    input:
        construct_all_rule(p_space),


include: workflow.source_path("components/preparation.references.smk")
include: workflow.source_path("components/preparation.primers.smk")
include: workflow.source_path("components/preparation.features.smk")
include: workflow.source_path("components/stats.pre_clean.smk")
include: workflow.source_path("components/clean.adapter_removal.smk")
include: workflow.source_path("components/clean.data_filter.smk")
include: workflow.source_path("components/clean.primer_removal.smk")
include: workflow.source_path("components/stats.post_clean.smk")
include: workflow.source_path("components/results.sequences.smk")
include: workflow.source_path("components/results.reporting_metrics.smk")
include: workflow.source_path("components/results.concatenations.smk")
include: workflow.source_path("components/results.combined.smk")


onsuccess:
    logging.info("[bold green]ViroConstrictor is finished with processing all the files in the given input directory.[/bold green]")
    logging.info("[bold green]Generating reports and shutting down...[/bold green]")
    return True


onerror:
    logging.error("[bold red]An error occurred and ViroConstrictor had to shut down.[/bold red]")
    logging.error("[bold red]Please check the input and logfiles for any abnormalities and try again.[/bold red]")
    return False
